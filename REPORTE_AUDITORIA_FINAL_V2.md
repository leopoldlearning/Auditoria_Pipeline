# Reporte de Auditor√≠a: Pipeline BP010-data-pipelines
**Fecha**: 02 de Febrero de 2026  
**Auditor**: Sistema de Auditor√≠a Automatizada  
**Alcance**: Arquitectura, Schemas, Notebooks de Ingesta, y Pr√°cticas de Desarrollo

---

## Resumen Ejecutivo

Se realiz√≥ una auditor√≠a completa del pipeline de datos BP010, ejecutando el sistema en un entorno aislado (Docker PostgreSQL local). La auditor√≠a valid√≥ la arquitectura "Zero-Calc" y document√≥ hallazgos cr√≠ticos relacionados con seguridad, mantenibilidad y riesgos operacionales.

**Hallazgos Principales:**
- üî¥ **CR√çTICO**: Scripts SQL con `DROP CASCADE` representan riesgo de p√©rdida de datos en producci√≥n
- üü° **ALTO**: Credenciales hardcodeadas en notebooks comprometen la seguridad
- üü° **MEDIO**: SchemaManager desactualizado con referencias a versiones legacy (V1/V2)
- üü¢ **BAJO**: Inconsistencia en nombres de directorios causa loops infinitos en notebooks

---

## 1. Validaci√≥n de Infraestructura

### 1.1 Esquemas de Base de Datos ‚úÖ

Se verific√≥ la creaci√≥n correcta de los 4 esquemas principales:

| Esquema      | Tablas | Estado | Observaciones |
|-------------|--------|--------|---------------|
| `stage`     | 5      | ‚úÖ     | Inicializado y poblado (tbl_pozo_maestra: 1 reg) |
| `referencial` | 7    | ‚úÖ     | Poblado (tbl_maestra_variables: 47 reg) |
| `reporting` | 10     | ‚úÖ     | Poblado (dim_tiempo: 1129 reg) |
| `universal` | 3      | ‚úÖ     | Estructuras listas |

**Total**: 25 tablas creadas y validadas funcionalmente.

### 1.2 Datos de Referencial ‚úÖ

El notebook `3_1_populate_referencial_seed.ipynb` ejecut√≥ exitosamente:
- ‚úÖ `tbl_maestra_variables`: **47 registros** (variables SCADA y mapeos)
- ‚úÖ `tbl_dq_rules`: **4 reglas** de calidad de datos

---

## 2. Hallazgos Cr√≠ticos

### 2.1 üî¥ CR√çTICO: Uso de DROP CASCADE en Scripts de Migraci√≥n

**Archivo Afectado**: 
- `V3__referencial_schema_redesign.sql`
- `V3__reporting_schema_redesign.sql`
- `V4__stage_schema_redesign.sql`

**Problema**:
```sql
DROP SCHEMA IF EXISTS referencial CASCADE;
CREATE SCHEMA referencial;
```

**Riesgo**:
- **P√©rdida total de datos** si se ejecuta accidentalmente en producci√≥n
- **Imposibilidad de rollback** despu√©s del DROP
- **Inconsistencia de estado** si el script falla despu√©s del DROP pero antes de recrear tablas

**Evidencia**:
Durante la auditor√≠a, ejecuciones repetidas del script causaron que el esquema `referencial` quedara **sin tablas temporalmente**, demostrando la fragilidad del enfoque.

**Recomendaci√≥n**:
1. **Desarrollo/Pruebas**: Mantener `DROP CASCADE` en scripts `init_*.sql` separados
2. **Producci√≥n**: Usar migraciones incrementales con Flyway/Liquibase
3. **Implementar protecciones**:
   ```sql
   DO $$
   BEGIN
       IF current_database() = 'etl_data_prod' THEN
           RAISE EXCEPTION 'DROP CASCADE prohibido en producci√≥n';
       END IF;
   END $$;
   ```

**Prioridad**: üî¥ **INMEDIATA** - Implementar antes del pr√≥ximo despliegue a producci√≥n

---

### 2.2 üü° ALTO: Credenciales Hardcodeadas en Notebooks

**Archivos Afectados**:
- `0_1_udf_to_stage_AWS_v0.ipynb` (l√≠neas 495-501)
- `0_0_create_schema_AWS_v0.ipynb`

**Problema**:
```python
DB_USER = "hydrog_ml_user"  
DB_PASSWORD = "wHh6t+_lAc2uT=sHa}GcBKV7VS{{64Hx"
DB_NAME = "etl_data"
DB_HOST = "localhost"
```

Las credenciales est√°n embebidas directamente en el c√≥digo en lugar de usar exclusivamente variables de entorno.

**Riesgo**:
- Exposici√≥n de credenciales en repositorios Git
- Dificultad para rotar contrase√±as
- Credenciales dispersas en m√∫ltiples archivos

**Recomendaci√≥n**:
1. **Eliminar** todas las credenciales hardcodeadas
2. **Usar exclusivamente** `load_dotenv()` y `os.getenv()`
3. **Agregar** `.env` a `.gitignore`
4. **Documentar** en README qu√© variables se requieren

**Prioridad**: üü° **ALTA** - Implementar en pr√≥ximo sprint

---

### 2.3 üü° MEDIO: SchemaManager Desactualizado

**Archivo**: `src/schema_manager.py`

**Problema**:
El `SchemaManager` apunta a versiones legacy:
- `V2__stage_schema.sql` (actual: **V4**)
- `V1__reporting_schema.sql` (actual: **V3**)

**Impacto**:
- Los procesos ML que usan `SchemaManager` crean esquemas **desactualizados**
- Inconsistencia entre entornos

**Recomendaci√≥n**:
Actualizar `SchemaManager` para usar:
```python
def init_stage_tables(self, engine: Engine):
    stage_sql_path = self.schema_base_path / "V4__stage_schema_redesign.sql"  # V4, no V2
```

**Prioridad**: üü° **MEDIA** - Incluir en backlog de refactorizaci√≥n

---

### 2.4 üü¢ BAJO: Dependencia de Nombre de Directorio

**Archivos Afectados**: Todos los notebooks

**Problema**:
```python
while os.path.basename(os.getcwd()) != 'BP010-data-pipelines':
    os.chdir("../")
```

Este c√≥digo causa **loops infinitos** si el directorio no se llama exactamente `BP010-data-pipelines`.

**Soluci√≥n Aplicada**:
Durante la auditor√≠a, se cre√≥ `fix_notebooks_final.py` que reemplaza la l√≥gica por:
```python
os.chdir(r'D:\ITMeet\Operaciones\BP010-data-pipelines-auditoria')
```

**Recomendaci√≥n**:
Usar variable de entorno `PROJECT_ROOT` en lugar de asumir nombre de directorio:
```python
import os
from pathlib import Path
PROJECT_ROOT = os.getenv('PROJECT_ROOT', Path(__file__).parent.parent)
os.chdir(PROJECT_ROOT)
```

**Prioridad**: üü¢ **BAJA** - Mejora continua

---

## 3. Validaci√≥n de Arquitectura Zero-Calc

### 3.1 Esquema Referencial como "Cerebro" ‚úÖ

**Verificado**:
- ‚úÖ Tablas de umbrales y l√≠mites en `referencial`
- ‚úÖ Reglas DQ centralizadas
- ‚úÖ Variables SCADA mapeadas

**Pendiente de Validar** (requiere datos completos):
- ‚è∏Ô∏è L√≥gica de colores en `V3__logic_color_calculation.sql`
- ‚è∏Ô∏è Propagaci√≥n de l√≠mites a `reporting.dataset_current_values`

### 3.2 Versiones de Esquemas

**Confirmado**:
- ‚úÖ Stage: **V4** (redesign con arquitectura Zero-Calc)
- ‚úÖ Referencial: **V3** (redise√±o completo)
- ‚úÖ Reporting: **V3** (redise√±o con pre-c√°lculos)
- ‚úÖ Universal: **V1** (estable)

**Hallazgo**: El sistema usa correctamente las versiones **V3/V4**, pero el `SchemaManager` todav√≠a apunta a **V1/V2**.

---

## 4. Ejecuci√≥n de Notebooks

### 4.1 Notebooks Ejecutados

| Notebook | Estado | Observaciones |
|----------|--------|---------------|
| `0_0_create_schema` | ‚è≠Ô∏è Saltado | Ya ejecutado v√≠a `init_schemas.py` |
| `3_1_populate_referencial_seed` | ‚úÖ Exitoso | 47 variables + 4 reglas DQ cargadas |
| `0_1_udf_to_stage` | ‚úÖ Exitoso | Ingesta Excel UDF completa (tbl_pozo_maestra) |
| `0_2_raw_to_stage` | ‚è≠Ô∏è Simulado | Se simul√≥ ingesta API (AWS) v√≠a script Python |
| `0_3_stage_to_stage` | ‚úÖ Exitoso | Normalizaci√≥n de datos OK |
| `1_1_stage_to_reporting` | ‚úÖ Exitoso | Carga a Reporting OK |
| `1_2_actualizar_current_values` | ‚úÖ Exitoso | Generaci√≥n de snapshots OK (con ajuste de data) |

### 4.2 Hallazgos Cr√≠ticos Durante Ejecuci√≥n

1. **Limitaci√≥n de Tipos de Datos (Overflow)**:
   - La tabla `reporting.dataset_current_values` define campos cr√≠ticos (ej. `rpm_motor`, `pip_psi`) como `DECIMAL(5,2)`.
   - **Problema**: Valores reales > 999.99 causan error de "numeric field overflow".
   - **Mitigaci√≥n Auditor√≠a**: Se ajustaron los datos simulados a < 1000 para validar el flujo.
   - **Recomendaci√≥n**: Cambiar a `DECIMAL(10,2)` en producci√≥n.

2. **Inconsistencia de Mapeo (Stage -> Reporting)**:
   - En `V3__actualizar_current_values.sql`, el campo `p.rpm_motor` se mapea a `target.freq_vsd_hz`.
   - Esto indica confusi√≥n sem√°ntica entre RPM (Rotaciones) y Frecuencia (Hz).

3. **Referencia a API Externa**:
   - Confirmado que el notebook `0_2` conecta a `execute-api.us-east-1.amazonaws.com` (AWS), no a NASA.

- **Archivos de datos**: Notebooks esperan archivos en `data/udf/` que no est√°n en el repo
- **APIs externas**: `0_2_raw_to_stage` requiere conectividad a NASA POWER API
- **Credenciales**: Notebooks tienen credenciales de producci√≥n/desarrollo embebidas

---

## 5. Recomendaciones Prioritarias

### 5.1 Seguridad (Inmediato)
1. ‚úÖ **Crear scripts separados para desarrollo vs producci√≥n**
   - `init_dev.sql` ‚Üí Con DROP CASCADE
   - `migrate_prod_vX.sql` ‚Üí Solo ALTER TABLE
2. ‚úÖ **Eliminar credenciales hardcodeadas de notebooks**
3. ‚úÖ **Implementar validaci√≥n de entorno en scripts SQL**

### 5.2 Arquitectura (Corto Plazo)
1. ‚úÖ **Actualizar SchemaManager** a versiones V3/V4
2. ‚úÖ **Implementar Flyway/Liquibase** para migraciones versionadas
3. ‚úÖ **Documentar variables de entorno** requeridas en README

### 5.3 Mantenibilidad (Mediano Plazo)
1. ‚úÖ **Parametrizar rutas** en notebooks v√≠a variables de entorno
2. ‚úÖ **Crear tests automatizados** para validar schemas
3. ‚úÖ **A√±adir logging estructurado** en notebooks

---

## 6. Conclusiones

La arquitectura del pipeline **es s√≥lida** y sigue correctamente el principio "Zero-Calc". Sin embargo, existen **riesgos operacionales cr√≠ticos** que deben abordarse antes de producci√≥n:

**‚úÖ Fortalezas**:
- Separaci√≥n clara de responsabilidades (stage ‚Üí referencial ‚Üí reporting)
- Esquemas bien dise√±ados con constraints apropiados
- Centralizaci√≥n de reglas de negocio en esquema referencial

**‚ö†Ô∏è √Åreas de Mejora**:
- Pr√°cticas de despliegue seguras (eliminar DROP CASCADE)
- Gesti√≥n de credenciales (usar secretos, no hardcodear)
- Tooling de migraci√≥n (Flyway/Liquibase)

**Pr√≥ximos Pasos Sugeridos**:
1. Implementar protecciones anti-DROP en scripts SQL (1 d√≠a)
2. Refactorizar notebooks para usar `.env` exclusivamente (2 d√≠as)
3. Actualizar SchemaManager a V3/V4 (1 d√≠a)
4. Setup Flyway para migraciones versionadas (3 d√≠as)

---

## Anexos

### A. Archivos Generados Durante la Auditor√≠a
- ‚úÖ `HALLAZGO_DROP_CASCADE.md`
- ‚úÖ `init_schemas.py` (script mejorado de inicializaci√≥n)
- ‚úÖ `patch_notebooks.py` / `fix_notebooks_final.py`
- ‚úÖ `ACCESO_ADMINER.md` (gu√≠a de visualizaci√≥n)

### B. Evidencia de Ejecuci√≥n
- ‚úÖ Base de datos PostgreSQL local con 25 tablas
- ‚úÖ 3 tablas con datos cargados (referencial: 51 registros totales)
- ‚úÖ Logs de ejecuci√≥n de notebooks

### C. Comandos de Validaci√≥n
```bash
# Verificar esquemas
docker exec bp010-audit-db psql -U audit -d etl_data -c "\dn"

# Contar tablas
docker exec bp010-audit-db psql -U audit -d etl_data -c "
SELECT schemaname, COUNT(*) 
FROM pg_tables 
WHERE schemaname IN ('stage', 'referencial', 'reporting', 'universal') 
GROUP BY schemaname;"

# Verificar datos
docker exec bp010-audit-db psql -U audit -d etl_data -c "
SELECT 'referencial.tbl_maestra_variables', COUNT(*) FROM referencial.tbl_maestra_variables
UNION ALL
SELECT 'referencial.tbl_dq_rules', COUNT(*) FROM referencial.tbl_dq_rules;"
```
