# Gu铆a de Replicaci贸n de Auditor铆a: BP010 Data Pipelines
> **Target Audience**: Agentes de IA / Ingenieros de Datos
> **Objetivo**: Replicar la auditor铆a t茅cnica del repositorio `BP010-data-pipelines` desde cero, asegurando un entorno aislado y resultados consistentes.

## 1. Principios de Auditor铆a (Aislamiento)
Para garantizar una auditor铆a segura, **NUNCA** ejecutes c贸digo directamente sobre el repositorio original ni uses la base de datos de producci贸n/desarrollo externa.
1.  Crea un directorio de auditor铆a separado (ej: `BP010-data-pipelines-auditoria`).
2.  Crea tu propio entorno Docker con PostgreSQL 15 local.
3.  Copia selectivamente los artefactos (`src`, `data`) del repo original al de auditor铆a.

## 2. Fase de Infraestructura (Setup)

### 2.1 Docker Compose
Crea un `docker-compose.yml` que levante:
-   **PostgreSQL 15**: Puerto mapeado (ej: `5433:5432` host:container).
-   **Adminer**: Para inspecci贸n visual r谩pida.
-   **Network**: Aislada.

### 2.2 Variables de Entorno (.env)
Configura un `.env` local. **CRTICO**: No uses las credenciales del repo original.
```ini
DB_USER=audit
DEV_DB_PASSWORD=audit
DB_HOST=localhost
DB_PORT=5433
DB_NAME=etl_data
```

## 3. Fase de An谩lisis y Correcci贸n de C贸digo (Patching)

Antes de ejecutar nada, debes corregir errores estructurales detectados en el c贸digo original:

### 3.1 Notebooks
Los notebooks `.ipynb` originales tienen dos problemas graves que debes parchear (autom谩ticamente v铆a script Python o `sed`):
1.  **Path Looping**: Tienen celdas que buscan recursivamente el directorio ra铆z. Reemplaza esa l贸gica por un simple `os.chdir(PROJECT_ROOT)`.
2.  **Credenciales Hardcodeadas**: Buscan usuarios/passwords fijos en el c贸digo (ej: "hydrog_ml_user"). Reemplaza todas las asignaciones `DB_USER = "..."` por `os.getenv('DB_USER')`.

### 3.2 SQL Schema Versions
El c贸digo Python (`SchemaManager`) puede apuntar a versiones antiguas (`V1`, `V2`).
-   **Acci贸n**: Inspecciona `src/sql/schema`. Usa las versiones m谩s altas disponibles (`V3`, `V4`) para la creaci贸n de tablas.
-   **Riesgo**: `DROP SCHEMA CASCADE` est谩 presente en scripts de migraci贸n. Bloqu茅alo o ejec煤talo solo en tu entorno Docker aislado.

## 4. Fase de Ingesta de Datos (DATA SOURCE)

Originalmente, este pipeline depend铆a de una API externa (AWS) sin credenciales disponibles. Tradicionalmente se usaba simulaci贸n, pero ahora contamos con datos extra铆dos manualmente.

### 4.1 Fuente de Verdad (Real vs Simulada)
- **Datos Reales**: Si est谩n disponibles, use los archivos ubicados en `D:\ITMeet\Operaciones\API Hydrog manual`. Estos archivos contienen la telemetr铆a real extra铆da v铆a script manual.
- **Simulaci贸n (Fallback)**: Si no hay acceso a los archivos reales, analice `src/sql/process/V1__stage_to_stage.sql` para extraer los `var_id` y generar datos < 1000 para evitar *Numeric Overflow*.

### 4.2 Importancia de la Capa de Calidad (tbl_pozo_scada_dq)
> [!IMPORTANT]
> **驴Por qu茅 es necesaria la tabla DQ en Stage?**
> A diferencia de otros sistemas donde la validaci贸n ocurre al final, aqu铆 la tabla `stage.tbl_pozo_scada_dq` act煤a como un **Gatekeeper (Guardi谩n)**:
> 1. **Zero-Noise**: Asegura que el Dashbord (`reporting`) no consuma basura.
> 2. **Trazabilidad**: Permite auditar qu茅 regla fall贸 (`regla_id`) para un dato espec铆fico sin tener que re-analizar el crudo.
> 3. **Consistencia Zero-Calc**: El script de l贸gica de colores lee el estado de DQ para decidir si muestra un valor o un aviso de "Dato No Confiable".

## 5. Fase de Ejecuci贸n (Pipeline Sequence)

Ejecuta los notebooks en este orden estricto (usando `nbconvert --inplace`):

1.  `0_1_udf_to_stage.ipynb`: Carga datos est谩ticos (Excel UDF).
2.  **[Ejecutar Script Simulaci贸n]**: Inyecta datos SCADA simulados.
3.  `0_3_stage_to_stage.ipynb`: Transforma landing -> stage tables.
4.  `1_1_stage_to_reporting.ipynb`: Mueve data a Reporting (Dims/Facts).
5.  `1_2_actualizar_current_values.ipynb`: Genera snapshot de KPIs.

## 6. Verificaci贸n de Resultados

Al finalizar, consulta la tabla `reporting.dataset_current_values`. Deber铆as ver:
-   1 registro para el pozo 5.
-   Datos poblados en columnas de producci贸n, presi贸n y estado.
-   **Hallazgo a Reportar**: Inconsistencia sem谩ntica (`rpm_motor` mapped to `freq_vsd_hz`) y limitaci贸n de tipos de datos (`DECIMAL(5,2)`).

---
*Esta gu铆a garantiza que cualquier agente inteligente pueda reproducir los hallazgos de seguridad y estabilidad sin acceso al entorno productivo real.*

## 7. Arquitectura Revelada y Hallazgos Finales (Post-Auditor铆a Profunda)

Tras una "cacer铆a" exhaustiva del c贸digo fuente, se ha descifrado la arquitectura real de producci贸n. Usa esta referencia para entender lo que est谩s auditando:

### 7.1 Mapa de Microservicios (Dual-Lambda)
El sistema no es un script monol铆tico, sino dos servicios serverless desacoplados que orquestan el flujo real:

1.  **Servicio de Ingesta (Stage Service)** 
    *   **Ubicaci贸n**: `docker/rds-stage-etl-project/etl_app/lambda_handler.py`.
    *   **Responsabilidad**: Ingesta API + Transformaci贸n Pivot.
    *   **Flujo**: Trigger -> `V1__raw_to_stage` (Vertical) -> `V1__stage_to_stage` (Horizontal).
    *   **Nota**: Este componente suele ser invisible en ejecuciones locales de notebooks.

2.  **Servicio de Reportes (Reporting Service)** 
    *   **Ubicaci贸n**: `docker/rds-reporting-etl-project/etl_app/lambda_handler.py`.
    *   **Responsabilidad**: C谩lculo de KPIs y Snapshot.
    *   **Flujo**: Trigger -> `V1__stage_to_reporting` -> `V3__actualizar_current_values`.

### 7.2 Genealog铆a del Dato (Lineage)
Es vital distinguir el origen de los datos para no confundir metadatos con telemetr铆a:

*   **Rama Est谩tica (Excel)**:
    *   Archivo `Formato1_Excel_Reservas.xlsx` -> `udf_to_stage` -> **`stage.tbl_pozo_maestra`**.
    *   *Prop贸sito*: Define la identidad del pozo (Nombre, Ubicaci贸n, Equipo Instalado).
*   **Rama Din谩mica (API/SCADA)**:
    *   API Externa -> `raw_to_stage` -> `landing` -> `stage_to_stage` -> **`stage.tbl_pozo_produccion`**.
    *   *Prop贸sito*: Define el estado operativo (Presi贸n, Flujo, Temperatura).

### 7.4 Hallazgo: Gaps en Orquestaci贸n (Horaria y DQ) [NUEVO]
Tras la auditor铆a profunda, se detectaron los siguientes "puntos ciegos" en la orquestaci贸n local:

1.  **Ingesta Horaria Desactivada**: Los notebooks locales invocan `sp_load_to_reporting` con `p_procesar_horario = FALSE` por defecto. Se requiere habilitar este flag expl铆citamente para ver datos en `reporting.fact_operaciones_horarias`.
2.  **DQ Engine Desconectado**: Existe la infraestructura para Calidad de Datos (`referencial.tbl_dq_rules` y `stage.tbl_pozo_scada_dq`), pero no hay un script Python o Stored Procedure que ejecute las validaciones en el formato V4 (Normalizado). Esto causa que el Dashboard muestre siempre `PASS` de forma err贸nea.

### 7.5 La Vulnerabilidad Cr铆tica (El "Eslab贸n D茅bil")
... (contenido anterior) ...


## 8. Documentaci贸n de Poblaci贸n de Tablas (Lineage)

Para que un auditor o agente de IA entienda el origen de los datos, siga esta matriz de poblaci贸n:

### 8.1 Capa Referencial (Cerebro del Sistema)
| Tabla | Origen Primario | Proceso de Carga |
| :--- | :--- | :--- |
| `tbl_maestra_variables` | `01_maestra_variables.csv` | `V3__referencial_seed_data.sql` |
| `tbl_dq_rules` | `02_reglas_calidad.csv` | `V3__referencial_seed_data.sql` |
| `tbl_limites_pozo` | `04_esquema_reporting_zero_calc.csv` | **Manual Patch (V4)** - Requerido para KPIs. |

### 8.2 Capa Stage (Datos Crudos y Pivoteados)
| Tabla | Origen Primario | Proceso de Carga |
| :--- | :--- | :--- |
| `tbl_pozo_maestra` | `Formato1_Excel_Reservas.xlsx` | `0_1_udf_to_stage_AWS_v0.ipynb` |
| `landing_scada_data` | API AWS (Prod) / Simulation (Audit) | `0_2_raw_to_stage_AWS_v0.ipynb` |
| `tbl_pozo_produccion`| `landing_scada_data` | `V1__stage_to_stage.sql` (Pivote EAV -> Wide) |

### 8.3 Capa Reporting (Consumo BI)
| Tabla | Origen Primario | Proceso de Carga |
| :--- | :--- | :--- |
| `dim_tiempo` / `dim_hora` | Scripts SQL DDL | Pobladas durante el SQL Init o SP. |
| `fact_operaciones_horarias`| `stage.tbl_pozo_produccion` | `sp_load_to_reporting(..., TRUE, ...)` |
| `fact_operaciones_diarias`| `stage.tbl_pozo_produccion` | `V1__stage_to_reporting.sql` |
| `fact_operaciones_mensuales`| `fact_operaciones_diarias` | `CALL reporting.sp_load_to_reporting(..., TRUE)` |
| `dataset_current_values` | `stage` + `referencial` | `V3__actualizar_current_values.sql` |

### 8.4 Capa Universal (IA/ML)
| Tabla | Estado | Observaci贸n |
| :--- | :--- | :--- |
| `ipr_resultados` | **Vac铆a** | Requiere ejecuci贸n de modelos externos no presentes en este repo core. |
| `arps_resultados_declinacion`| **Vac铆a** | Pendiente integraci贸n de flujos de predicci贸n. |

> [!TIP]
> **Modificaci贸n Sugerida**: Automatizar la carga de `tbl_limites_pozo` en el script `generate_referencial_seed.py` para evitar tablas vac铆as en nuevas instalaciones.

## 9. El "Golden Flow": Orquestaci贸n Maestra Final
Para asegurar que el equipo de Desarrollo y Producci贸n pueda correr todo el pipeline con datos reales y validaciones autom谩ticas, se ha creado el orquestador unificado.

### 9.1 La Secuencia Maestra
El archivo `MASTER_PIPELINE_RUNNER.py` coordina las 7 fases del sistema en el orden correcto:

1.  **DDL Setup**: Crea los 4 esquemas (V3/V4).
2.  **Master Data**: Carga pozos y variables desde Excel/Config.
3.  **Real Ingestion**: Toma los archivos de `API Hydrog manual`.
4.  **Pivot transform**: Convierte telemetr铆a cruda a formato pozo-columna.
5.  **DQ Engine (EL GUARDIN)**: Ejecuta `sp_execute_dq_validation`. **Este paso marca cada dato como PASS/FAIL antes de llegar a Reporting**.
6.  **Reporting Layers**: Genera hechos Horarios, Diarios y Mensuales.
7.  **Snapshot Final**: Actualiza `dataset_current_values` con los 煤ltimos KPIs y el estado de DQ.

### 9.2 Instrucciones de Uso
1.  Coloque los extractos de la API en `D:\ITMeet\Operaciones\API Hydrog manual`.
2.  Active el entorno virtual: `auditor\Scripts\activate`.
3.  Ejecute: `python MASTER_PIPELINE_RUNNER.py`.
4.  Visualice los resultados en Adminer:
    -   `stage.tbl_pozo_scada_dq`: Resultados de calidad.
    -   `reporting.dataset_current_values`: KPIs finales validados.

### 9.3 Soluci贸n de Problemas y Consideraciones T茅cnicas [NUEVO]

Para una replicaci贸n exitosa en entornos Windows/IA, tenga en cuenta:

> [!WARNING]
> **Codificaci贸n SQL (Encoding)**: Los scripts SQL originales pueden contener acentos o caracteres especiales. El `init_schemas.py` ha sido configurado para leer en `latin-1` y transmitir en `utf-8`. Si crea nuevos scripts, aseg煤rese de usar una codificaci贸n consistente para evitar errores de `invalid byte sequence`.

> [!IMPORTANT]
> **Compatibilidad de Consola (Unicode)**: Se han eliminado los Emojis de los logs del orquestador (`MASTER_PIPELINE_RUNNER.py`) para evitar el error `UnicodeEncodeError` al redirigir la salida a archivos `.log` en sistemas Windows. Se recomienda usar prefijos como `[OK]` o `[ERROR]`.

> [!NOTE]
> **Type Casting en SQL**: Al invocar procedimientos almacenados (como el motor DQ) desde Python, use casting expl铆cito (ej: `'2026-02-01'::DATE`) para evitar ambig眉edades de tipo `unknown` en PostgreSQL.

---
> [!TIP]
> **Consideraci贸n Final**: Este flujo garantiza que ning煤n dato llegue al Dashboard sin haber pasado por el filtro de reglas del esquema `Referencial`.
