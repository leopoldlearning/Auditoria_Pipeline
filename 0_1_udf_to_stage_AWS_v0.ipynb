{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961a9b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:02.971465Z",
     "iopub.status.busy": "2026-02-03T18:17:02.971465Z",
     "iopub.status.idle": "2026-02-03T18:17:02.990378Z",
     "shell.execute_reply": "2026-02-03T18:17:02.990378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: D:\\ITMeet\\Operaciones\\BP010-data-pipelines-auditoria\n",
      " Current working directory: D:\\ITMeet\\Operaciones\\BP010-data-pipelines-auditoria\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Asegurarse que el directorio de trabajo es la ra铆z del proyecto\n",
    "import os\n",
    "os.chdir(r'D:\\ITMeet\\Operaciones\\BP010-data-pipelines-auditoria')\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "    \n",
    "print(f\" Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8a3941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:02.990378Z",
     "iopub.status.busy": "2026-02-03T18:17:02.990378Z",
     "iopub.status.idle": "2026-02-03T18:17:04.019935Z",
     "shell.execute_reply": "2026-02-03T18:17:04.019935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, pool, insert\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, Any\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configuraci贸n b谩sica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f8442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.022296Z",
     "iopub.status.busy": "2026-02-03T18:17:04.022296Z",
     "iopub.status.idle": "2026-02-03T18:17:04.043084Z",
     "shell.execute_reply": "2026-02-03T18:17:04.043084Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReservasDataIngestor:\n",
    "    \"\"\"\n",
    "    Clase para ingestar datos de reservas desde Excel a tablas PostgreSQL.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, excel_path: str, db_connection_string: str):\n",
    "        \"\"\"\n",
    "        Inicializa el ingestor de datos.\n",
    "        \n",
    "        Args:\n",
    "            excel_path: Ruta al archivo Excel con los datos\n",
    "            db_connection_string: String de conexi贸n a PostgreSQL\n",
    "        \"\"\"\n",
    "        self.excel_path = excel_path\n",
    "        self.engine = create_engine(db_connection_string)\n",
    "        \n",
    "        # Mapeo de IDs a columnas para tbl_pozo_maestra\n",
    "        # Sincronizado con V4__stage_schema_redesign.sql\n",
    "        self.mapeo_maestros = {\n",
    "            1: 'well_id',\n",
    "            2: 'profundidad_completacion',\n",
    "            3: 'tipo_pozo',\n",
    "            4: 'coordenadas_pozo',\n",
    "            5: 'api_number',\n",
    "            12: 'cliente',\n",
    "            13: 'pais',\n",
    "            14: 'region',\n",
    "            15: 'campo',\n",
    "            16: 'nombre_yacimiento',\n",
    "            17: 'permeabilidad_abosluta',\n",
    "            19: 'radio_pozo',\n",
    "            20: 'radio_drenaje',\n",
    "            21: 'presion_inicial_yacimiento',\n",
    "            22: 'temperatura_yacimiento',\n",
    "            23: 'espesor_formacion',\n",
    "            26: 'intervalo_disparos',\n",
    "            28: 'permeabilidad_horizontal',\n",
    "            33: 'diametro_embolo_bomba',\n",
    "            37: 'tipo_levantamiento',\n",
    "            38: 'profundidad_vertical_yacimiento',\n",
    "            39: 'profundidad_vertical_bomba',\n",
    "            42: 'longitud_carrera_nominal_unidad_in', #nombre actualizado\n",
    "            43: 'potencia_nominal_motor',\n",
    "            44: 'corriente_nominal_motor',\n",
    "            45: 'voltaje_nominal',\n",
    "            46: 'carga_nominal_unidad',\n",
    "            47: 'carga_minima_nominal_sarta',\n",
    "            49: 'nombre_pozo',\n",
    "            72: 'peso_sarta_aire',  # Agregado - Rod Weight in Air\n",
    "            75: 'carga_maxima_fluido_api',  # Agregado - API Max Fluid Load\n",
    "            85: 'frecuencia_nominal_motor',\n",
    "            87: 'num_software'\n",
    "        }\n",
    "        \n",
    "        # Mapeo de IDs a columnas para tbl_pozo_reservas\n",
    "        # Sincronizado con V4__stage_schema_redesign.sql\n",
    "        self.mapeo_reservas = {\n",
    "            1: 'well_id',\n",
    "            10: 'gravedad_api',\n",
    "            18: 'viscosidad_crudo',\n",
    "            24: 'presion_burbujeo',\n",
    "            25: 'presion_estatica_yacimiento',\n",
    "            27: 'presion_fondo_fluyente_critico',\n",
    "            29: 'viscosidad_superficie',\n",
    "            30: 'factor_volumetrico',\n",
    "            31: 'otros_pvt',  # Agregado - Otros PVT\n",
    "            32: 'wc_critico',\n",
    "            48: 'llenado_bomba_minimo',\n",
    "            58: 'contenido_finos',\n",
    "            # 59: 'nivel_fluido_dinamico',  # REMOVIDO - No existe en schema V4\n",
    "            63: 'gravedad_especifica_agua',\n",
    "            128: 'reserva_inicial_teorica',  # Agregado\n",
    "            152: 'q_esperado',\n",
    "            159: 'radio_equivalente',\n",
    "            160: 'longitud_horizontal',\n",
    "            161: 'factor_dano',\n",
    "            162: 'permeabilidad_vertical',\n",
    "            128: 'reserva_inicial_teorica' #agregado\n",
    "        }\n",
    "    \n",
    "    def transformar_datos(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        mapeo: Dict[int, str]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transforma datos de formato largo (ID, Valor) a formato ancho (columnas).\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame con columnas ['ID', 'Categor铆a', 'Nombre', 'Valor']\n",
    "            mapeo: Diccionario de mapeo ID -> nombre_columna\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame transformado con columnas mapeadas\n",
    "        \"\"\"\n",
    "        logger.info(f\"Transformando datos de formato 1\")\n",
    "        \n",
    "        # Filtrar solo los IDs que nos interesan\n",
    "        df_filtrado = df[df['ID'].isin(mapeo.keys())].copy()\n",
    "        \n",
    "        # Crear diccionario con los valores\n",
    "        datos_transformados = {}\n",
    "        for _, row in df_filtrado.iterrows():\n",
    "            id_campo = int(row['ID'])\n",
    "            nombre_columna = mapeo[id_campo]\n",
    "            valor = row['Valor']\n",
    "            \n",
    "            # Convertir valores num茅ricos\n",
    "            if pd.notna(valor):\n",
    "                try:\n",
    "                    # Intentar convertir a float si es posible\n",
    "                    if isinstance(valor, str) and valor.replace('.', '').replace('-', '').replace(\"'\", \"\").isdigit():\n",
    "                        valor = float(valor.replace(\"'\", \"\"))\n",
    "                    elif isinstance(valor, (int, float)):\n",
    "                        valor = float(valor)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            datos_transformados[nombre_columna] = [valor]\n",
    "        \n",
    "        # Crear DataFrame\n",
    "        df_resultado = pd.DataFrame(datos_transformados)\n",
    "        \n",
    "        logger.info(f\"Transformaci贸n completada. Columnas: {len(df_resultado.columns)}\")\n",
    "        return df_resultado\n",
    "    \n",
    "    def preparar_datos_maestros(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Lee y prepara datos de la hoja \"Datos Maestros\" para tbl_pozo_maestra.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame preparado para inserci贸n\n",
    "        \"\"\"\n",
    "        logger.info(\"Preparando datos maestros...\")\n",
    "        \n",
    "        # Leer datos\n",
    "        df_raw = pd.read_excel(self.excel_path, sheet_name=\"Datos Maestros\")\n",
    "        \n",
    "        # Transformar formato\n",
    "        df_maestros = self.transformar_datos(df_raw, self.mapeo_maestros)\n",
    "        \n",
    "        # Agregar campos requeridos\n",
    "        df_maestros['fecha_registro'] = datetime.now().date()\n",
    "        # fecha_creacion se manejar谩 con DEFAULT CURRENT_TIMESTAMP en la BD\n",
    "        \n",
    "        # Validar well_id\n",
    "        if 'well_id' not in df_maestros.columns:\n",
    "            raise ValueError(\"No se encontr贸 well_id en los datos maestros\")\n",
    "        \n",
    "        # Convertir well_id a int\n",
    "        df_maestros['well_id'] = df_maestros['well_id'].astype(int)\n",
    "        \n",
    "               \n",
    "        logger.info(f\"Datos maestros preparados: {df_maestros.shape}\")\n",
    "        \n",
    "        return df_maestros\n",
    "    \n",
    "    def preparar_datos_reservas(self, well_id: int = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Lee y prepara datos de la hoja \"Datos Reserva\" para tbl_pozo_reservas.\n",
    "        \n",
    "        Args:\n",
    "            well_id: ID del pozo (si no est谩 en los datos, se puede pasar manualmente)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame preparado para inserci贸n\n",
    "        \"\"\"\n",
    "        logger.info(\"Preparando datos de reservas...\")\n",
    "        \n",
    "        # Leer datos\n",
    "        df_raw = pd.read_excel(self.excel_path, sheet_name=\"Datos Reserva\")\n",
    "        \n",
    "        # Transformar formato\n",
    "        df_reservas = self.transformar_datos(df_raw, self.mapeo_reservas)\n",
    "        \n",
    "        # Manejar well_id\n",
    "        if 'well_id' in df_reservas.columns:\n",
    "            df_reservas['well_id'] = df_reservas['well_id'].astype(int)\n",
    "            if df_reservas['well_id'].iloc[0] == 0 and well_id is not None:\n",
    "                df_reservas['well_id'] = well_id\n",
    "        elif well_id is not None:\n",
    "            df_reservas['well_id'] = well_id\n",
    "        else:\n",
    "            raise ValueError(\"Se requiere well_id para datos de reserva\")\n",
    "        \n",
    "        # Agregar fecha_registro\n",
    "        df_reservas['fecha_registro'] = datetime.now().date()\n",
    "        \n",
    "        logger.info(f\"Datos de reservas preparados: {df_reservas.shape}\")\n",
    "        return df_reservas\n",
    "    \n",
    "    def validar_datos(self, df: pd.DataFrame, tabla: str) -> bool:\n",
    "        \"\"\"\n",
    "        Valida los datos antes de la inserci贸n.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a validar\n",
    "            tabla: Nombre de la tabla destino\n",
    "            \n",
    "        Returns:\n",
    "            True si la validaci贸n es exitosa\n",
    "        \"\"\"\n",
    "        logger.info(f\"Validando datos para {tabla}...\")\n",
    "        \n",
    "        errores = []\n",
    "        \n",
    "        # Validaciones para tbl_pozo_maestra\n",
    "        if tabla == \"tbl_pozo_maestra\":\n",
    "            if 'well_id' not in df.columns:\n",
    "                errores.append(\"Falta columna well_id\")\n",
    "            if 'nombre_pozo' not in df.columns:\n",
    "                errores.append(\"Falta columna nombre_pozo\")\n",
    "            if 'fecha_registro' not in df.columns:\n",
    "                errores.append(\"Falta columna fecha_registro\")\n",
    "                \n",
    "        # Validaciones para tbl_pozo_reservas\n",
    "        elif tabla == \"tbl_pozo_reservas\":\n",
    "            if 'well_id' not in df.columns:\n",
    "                errores.append(\"Falta columna well_id\")\n",
    "            if 'fecha_registro' not in df.columns:\n",
    "                errores.append(\"Falta columna fecha_registro\")\n",
    "        \n",
    "        # Validar valores nulos en columnas cr铆ticas\n",
    "        if 'well_id' in df.columns and df['well_id'].isna().any():\n",
    "            errores.append(\"well_id contiene valores nulos\")\n",
    "        \n",
    "        if errores:\n",
    "            logger.error(f\"Errores de validaci贸n:\\n\" + \"\\n\".join(f\"  - {e}\" for e in errores))\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"Validaci贸n exitosa para {tabla}\")\n",
    "        return True\n",
    "    \n",
    "    def insertar_datos_maestros(self, df: pd.DataFrame, mode: str = 'append') -> bool:\n",
    "        \"\"\"\n",
    "        Inserta datos en tbl_pozo_maestra.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame con datos preparados\n",
    "            mode: 'append' o 'replace'\n",
    "            \n",
    "        Returns:\n",
    "            True si la inserci贸n fue exitosa\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Insertando datos maestros...\")\n",
    "            \n",
    "            # Validar antes de insertar\n",
    "            if not self.validar_datos(df, \"tbl_pozo_maestra\"):\n",
    "                return False\n",
    "            \n",
    "            # Insertar en la base de datos\n",
    "            df.to_sql(\n",
    "                name='tbl_pozo_maestra',\n",
    "                schema='stage',\n",
    "                con=self.engine,\n",
    "                if_exists=mode,\n",
    "                index=False,\n",
    "                method='multi',\n",
    "                chunksize=1000\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"{len(df)} registro(s) insertado(s) en stage.tbl_pozo_maestra\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error al insertar datos maestros: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def insertar_datos_reservas(self, df: pd.DataFrame, mode: str = 'append') -> bool:\n",
    "        \"\"\"\n",
    "        Inserta datos en tbl_pozo_reservas.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame con datos preparados\n",
    "            mode: 'append' o 'replace'\n",
    "            \n",
    "        Returns:\n",
    "            True si la inserci贸n fue exitosa\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Insertando datos de reservas...\")\n",
    "            \n",
    "            # Validar antes de insertar\n",
    "            if not self.validar_datos(df, \"tbl_pozo_reservas\"):\n",
    "                return False\n",
    "            \n",
    "            # Insertar en la base de datos\n",
    "            df.to_sql(\n",
    "                name='tbl_pozo_reservas',\n",
    "                schema='stage',\n",
    "                con=self.engine,\n",
    "                if_exists=mode,\n",
    "                index=False,\n",
    "                method='multi',\n",
    "                chunksize=1000\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"{len(df)} registro(s) insertado(s) en stage.tbl_pozo_reservas\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error al insertar datos de reservas: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def ejecutar_ingesta_completa(self, well_id_override: int = None) -> Dict[str, bool]:\n",
    "        \"\"\"\n",
    "        Ejecuta el proceso completo de ingesta.\n",
    "        \n",
    "        Args:\n",
    "            well_id_override: ID del pozo a usar (opcional, si los datos tienen well_id=0)\n",
    "            \n",
    "        Returns:\n",
    "            Diccionario con status de cada inserci贸n\n",
    "        \"\"\"\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"INICIANDO PROCESO DE INGESTA DE DATOS\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        resultados = {\n",
    "            'maestros': False,\n",
    "            'reservas': False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # 1. Preparar e insertar datos maestros\n",
    "            df_maestros = self.preparar_datos_maestros()\n",
    "            \n",
    "            # Obtener well_id actual\n",
    "            current_well_id = int(df_maestros['well_id'].iloc[0])\n",
    "            if well_id_override:\n",
    "                df_maestros['well_id'] = well_id_override\n",
    "                current_well_id = well_id_override\n",
    "            \n",
    "            resultados['maestros'] = self.insertar_datos_maestros(df_maestros)\n",
    "            \n",
    "            # 2. Preparar e insertar datos de reservas\n",
    "            if resultados['maestros']:\n",
    "                df_reservas = self.preparar_datos_reservas(well_id=current_well_id)\n",
    "                resultados['reservas'] = self.insertar_datos_reservas(df_reservas)\n",
    "            \n",
    "            # Resumen final\n",
    "            logger.info(\"=\"*80)\n",
    "            logger.info(\"RESUMEN DE INGESTA\")\n",
    "            logger.info(\"=\"*80)\n",
    "            logger.info(f\"Datos Maestros: {'EXITOSO' if resultados['maestros'] else 'FALLIDO'}\")\n",
    "            logger.info(f\"Datos Reservas: {'EXITOSO' if resultados['reservas'] else 'FALLIDO'}\")\n",
    "            logger.info(\"=\"*80)\n",
    "            \n",
    "            return resultados\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error en proceso de ingesta: {str(e)}\")\n",
    "            return resultados\n",
    "    \n",
    "    def generar_reporte_datos(self) -> None:\n",
    "        \"\"\"\n",
    "        Genera un reporte de los datos en el Excel para revisi贸n.\n",
    "        \"\"\"\n",
    "        logger.info(\"Generando reporte de datos...\")\n",
    "        \n",
    "        # Leer ambas hojas\n",
    "        df_maestros = pd.read_excel(self.excel_path, sheet_name=\"Datos Maestros\")\n",
    "        df_reservas = pd.read_excel(self.excel_path, sheet_name=\"Datos Reserva\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"REPORTE DE DATOS - FORMATO1_EXCEL_RESERVAS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(\"\\n DATOS MAESTROS:\")\n",
    "        print(f\"   Total campos: {len(df_maestros)}\")\n",
    "        print(f\"   Campos con datos: {df_maestros['Valor'].notna().sum()}\")\n",
    "        print(f\"   Campos sin datos: {df_maestros['Valor'].isna().sum()}\")\n",
    "        \n",
    "        print(\"\\n DATOS RESERVAS:\")\n",
    "        print(f\"   Total campos: {len(df_reservas)}\")\n",
    "        print(f\"   Campos con datos: {df_reservas['Valor'].notna().sum()}\")\n",
    "        print(f\"   Campos sin datos: {df_reservas['Valor'].isna().sum()}\")\n",
    "        \n",
    "        print(\"\\nDISTRIBUCIN POR CATEGORA (Datos Maestros):\")\n",
    "        print(df_maestros['Categor铆a'].value_counts())\n",
    "        \n",
    "        print(\"\\nDISTRIBUCIN POR CATEGORA (Datos Reservas):\")\n",
    "        print(df_reservas['Categor铆a'].value_counts())\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbb97c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.043084Z",
     "iopub.status.busy": "2026-02-03T18:17:04.043084Z",
     "iopub.status.idle": "2026-02-03T18:17:04.049208Z",
     "shell.execute_reply": "2026-02-03T18:17:04.049208Z"
    }
   },
   "outputs": [],
   "source": [
    "def execute_sql(engine, esquema_stage_sql):\n",
    "    \"\"\"\n",
    "    Ejecuta el DDL de Stage para crear todas las tablas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "\n",
    "            connection.execute(text(esquema_stage_sql))\n",
    "            \n",
    "            connection.commit()\n",
    "        logger.info(\"consulta ejecutada exitosamente.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al crear tablas de Stage: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0c7cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.050744Z",
     "iopub.status.busy": "2026-02-03T18:17:04.050744Z",
     "iopub.status.idle": "2026-02-03T18:17:04.054178Z",
     "shell.execute_reply": "2026-02-03T18:17:04.054178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage Database URL: postgresql+psycopg2://audit:audit@localhost:5433/etl_data\n"
     ]
    }
   ],
   "source": [
    "# Es buena pr谩ctica usar variables de entorno para las credenciales\n",
    "DB_USER = os.getenv(\"DB_USER\", \"audit\")\n",
    "DB_PASSWORD = os.getenv(\"DEV_DB_PASSWORD\", \"audit\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"etl_data\")\n",
    "\n",
    "# --- PARMETROS DEL TNEL SSH ---\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "\n",
    "# 1. Construir la cadena de conexi贸n\n",
    "STAGE_DATABASE_URL = (\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@\"\n",
    "    f\"{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "print(f\"Stage Database URL: {STAGE_DATABASE_URL}\")\n",
    "\n",
    "EXCEL_PATH = \"data/udf/Formato1_Excel_Reservas.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24759a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.054178Z",
     "iopub.status.busy": "2026-02-03T18:17:04.054178Z",
     "iopub.status.idle": "2026-02-03T18:17:04.131531Z",
     "shell.execute_reply": "2026-02-03T18:17:04.131531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Crear el motor y ejecutar\n",
    "stage_engine = create_engine(STAGE_DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130e92f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.134237Z",
     "iopub.status.busy": "2026-02-03T18:17:04.134237Z",
     "iopub.status.idle": "2026-02-03T18:17:04.158081Z",
     "shell.execute_reply": "2026-02-03T18:17:04.158081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with stage_engine.connect() as connection:\n",
    "    response = connection.execute(text(\"SELECT * FROM stage.tbl_pozo_maestra;\"))\n",
    "\n",
    "response.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8ea8fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.158081Z",
     "iopub.status.busy": "2026-02-03T18:17:04.158081Z",
     "iopub.status.idle": "2026-02-03T18:17:04.166289Z",
     "shell.execute_reply": "2026-02-03T18:17:04.166289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with stage_engine.connect() as connection:\n",
    "    response = connection.execute(text(\"SELECT * FROM stage.tbl_pozo_reservas;\"))\n",
    "\n",
    "response.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6dfa186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.166289Z",
     "iopub.status.busy": "2026-02-03T18:17:04.166289Z",
     "iopub.status.idle": "2026-02-03T18:17:04.170882Z",
     "shell.execute_reply": "2026-02-03T18:17:04.170882Z"
    }
   },
   "outputs": [],
   "source": [
    "ingestor = ReservasDataIngestor(\n",
    "        excel_path=EXCEL_PATH,\n",
    "        db_connection_string=STAGE_DATABASE_URL\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed559b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.170882Z",
     "iopub.status.busy": "2026-02-03T18:17:04.170882Z",
     "iopub.status.idle": "2026-02-03T18:17:04.537751Z",
     "shell.execute_reply": "2026-02-03T18:17:04.537751Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,170 - __main__ - INFO - Generando reporte de datos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REPORTE DE DATOS - FORMATO1_EXCEL_RESERVAS\n",
      "================================================================================\n",
      "\n",
      " DATOS MAESTROS:\n",
      "   Total campos: 31\n",
      "   Campos con datos: 31\n",
      "   Campos sin datos: 0\n",
      "\n",
      " DATOS RESERVAS:\n",
      "   Total campos: 18\n",
      "   Campos con datos: 18\n",
      "   Campos sin datos: 0\n",
      "\n",
      "DISTRIBUCIN POR CATEGORA (Datos Maestros):\n",
      "Categor铆a\n",
      "Equipo            12\n",
      "Yacimiento         9\n",
      "Completaci贸n       4\n",
      "Pozo               4\n",
      "Identificaci贸n     1\n",
      "Administrativo     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "DISTRIBUCIN POR CATEGORA (Datos Reservas):\n",
      "Categor铆a\n",
      "Fluidos         8\n",
      "Producci贸n      3\n",
      "Yacimiento      3\n",
      "Equipo          2\n",
      "Completaci贸n    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "ingestor.generar_reporte_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c96e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.537751Z",
     "iopub.status.busy": "2026-02-03T18:17:04.537751Z",
     "iopub.status.idle": "2026-02-03T18:17:04.643219Z",
     "shell.execute_reply": "2026-02-03T18:17:04.643219Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,537 - __main__ - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,537 - __main__ - INFO - INICIANDO PROCESO DE INGESTA DE DATOS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,537 - __main__ - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,537 - __main__ - INFO - Preparando datos maestros...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,554 - __main__ - INFO - Transformando datos de formato 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,554 - __main__ - INFO - Transformaci贸n completada. Columnas: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,554 - __main__ - INFO - Datos maestros preparados: (1, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,554 - __main__ - INFO - Insertando datos maestros...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,554 - __main__ - INFO - Validando datos para tbl_pozo_maestra...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,554 - __main__ - INFO - Validaci贸n exitosa para tbl_pozo_maestra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,606 - __main__ - INFO - 1 registro(s) insertado(s) en stage.tbl_pozo_maestra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,606 - __main__ - INFO - Preparando datos de reservas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,617 - __main__ - INFO - Transformando datos de formato 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,627 - __main__ - INFO - Transformaci贸n completada. Columnas: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,627 - __main__ - INFO - Datos de reservas preparados: (1, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,627 - __main__ - INFO - Insertando datos de reservas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,627 - __main__ - INFO - Validando datos para tbl_pozo_reservas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,632 - __main__ - INFO - Validaci贸n exitosa para tbl_pozo_reservas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - 1 registro(s) insertado(s) en stage.tbl_pozo_reservas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - RESUMEN DE INGESTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - Datos Maestros: EXITOSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - Datos Reservas: EXITOSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-03 15:17:04,638 - __main__ - INFO - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "resultados = ingestor.ejecutar_ingesta_completa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e07e84d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T18:17:04.643219Z",
     "iopub.status.busy": "2026-02-03T18:17:04.643219Z",
     "iopub.status.idle": "2026-02-03T18:17:04.650844Z",
     "shell.execute_reply": "2026-02-03T18:17:04.650844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'State Blanco 58 A003', 'SWORDFISH ENERGY', 'USA', 'PECOS VALLEY', 'PECOS', '42-371-39760-01', 'Latitud: 31.22205 & Longitud: -102.98802', 'HORIZONTAL', Decimal('14278.0'), \"9330' - 14278'\", Decimal('4.67'), Decimal('860.0'), 'SIN INFO', Decimal('50.0'), Decimal('50.0'), Decimal('700.0'), Decimal('6130.0'), Decimal('225.0'), 'Hydralift T4', Decimal('10200.0'), Decimal('8491.0'), Decimal('2.0'), Decimal('360.0'), Decimal('125.0'), Decimal('150.0'), Decimal('460.0'), Decimal('60.0'), Decimal('40000.0'), Decimal('84184.0'), '810021.368', None, None, datetime.date(2026, 2, 3), datetime.datetime(2026, 2, 3, 18, 17, 4, 595796))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with stage_engine.connect() as connection:\n",
    "    response = connection.execute(text(\"SELECT * FROM stage.tbl_pozo_maestra;\"))\n",
    "\n",
    "response.fetchall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
